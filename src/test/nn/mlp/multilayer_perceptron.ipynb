{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 158.442778678\n",
      "Epoch: 0002 cost= 40.613929180\n",
      "Epoch: 0003 cost= 25.822184559\n",
      "Epoch: 0004 cost= 17.897572664\n",
      "Epoch: 0005 cost= 12.819076778\n",
      "Epoch: 0006 cost= 9.410799195\n",
      "Epoch: 0007 cost= 7.029883783\n",
      "Epoch: 0008 cost= 5.139968872\n",
      "Epoch: 0009 cost= 4.014337767\n",
      "Epoch: 0010 cost= 2.919351569\n",
      "Epoch: 0011 cost= 2.162515730\n",
      "Epoch: 0012 cost= 1.561620276\n",
      "Epoch: 0013 cost= 1.280861558\n",
      "Epoch: 0014 cost= 0.965519427\n",
      "Epoch: 0015 cost= 0.771344704\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9448\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    \n",
    "    # Backup params\n",
    "    trained_weights = sess.run(weights)\n",
    "    trained_biases = sess.run(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Param \"W1\"\n",
      "(256, 784)\n",
      "[  1.26700139e+00  -4.43212658e-01   6.09928966e-01  -8.01519334e-01\n",
      "   1.01956987e+00   7.54097462e-01   7.20799923e-01  -4.41826105e-01\n",
      "   3.08871448e-01   2.26510823e-01   4.19632226e-01  -1.22040339e-01\n",
      "  -1.97065139e+00   3.34972888e-01   1.63647190e-01   2.54302323e-01\n",
      "   2.84723341e-01   6.30752385e-01   3.88494730e-01   6.61761284e-01\n",
      "  -1.89316034e+00   1.62547350e+00   2.27689631e-02  -2.48122141e-01\n",
      "  -7.87550092e-01   2.54230469e-01  -3.10872551e-02   4.58284795e-01\n",
      "   5.86339653e-01  -2.06867695e-01  -1.08969879e+00   1.64718223e+00\n",
      "  -1.95504740e-01  -1.42129228e-01  -5.54778337e-01   4.06386778e-02\n",
      "   1.57056856e+00  -3.81438583e-01  -1.82694852e-01   2.82075644e-01\n",
      "   1.56796181e+00   2.68388212e-01   2.34907174e+00  -2.70374883e-02\n",
      "   2.84780622e-01  -4.22200412e-01   1.89768600e+00   4.48873162e-01\n",
      "   1.40869927e+00   9.71986949e-01   1.99938107e+00  -5.90975471e-02\n",
      "  -8.22637022e-01  -4.97181237e-01  -9.37261939e-01   7.65104771e-01\n",
      "  -1.39402974e+00  -2.04937887e+00   1.82359189e-01   5.00726879e-01\n",
      "   5.24408340e-01  -8.68014544e-02   1.34762609e+00   3.21593910e-01\n",
      "  -2.53339708e-01   1.64501965e+00  -1.69757712e+00   2.00832462e+00\n",
      "   8.47606361e-01   3.67827535e-01   2.83821702e-01  -1.04244545e-01\n",
      "  -8.66973341e-01  -7.01127201e-02   3.75896841e-01  -7.90240765e-01\n",
      "   6.69607103e-01  -3.69465888e-01  -8.56851488e-02  -1.25371420e+00\n",
      "   6.14503086e-01  -1.39499068e+00   2.23236799e-01   4.27282125e-01\n",
      "   7.65551686e-01   6.04476146e-02  -6.41739070e-02  -1.50855112e+00\n",
      "  -4.38544631e-01  -9.96628925e-02   1.03042543e+00   7.68508971e-01\n",
      "   5.38065195e-01   1.06381369e+00  -1.45408195e-02   2.23913997e-01\n",
      "  -6.74115837e-01  -1.76335800e+00  -7.46127009e-01  -8.35124850e-01\n",
      "  -1.18577492e+00   4.26022857e-01  -8.90587196e-02   3.58970612e-01\n",
      "   1.50284934e+00  -1.08625591e+00   1.73575485e+00   6.35380983e-01\n",
      "   5.80964088e-01  -1.62279582e+00  -1.16283605e-02   3.45897436e-01\n",
      "   2.06454471e-01  -1.62255514e+00  -1.39461005e+00  -7.66530573e-01\n",
      "   5.83408892e-01  -9.99608219e-01   2.22389519e-01  -4.04204160e-01\n",
      "   1.40729159e-01  -1.38541830e+00  -5.36968364e-05   9.13054705e-01\n",
      "   7.04263747e-02   1.45345032e+00  -1.01982558e+00   1.02246916e+00\n",
      "  -1.96391392e+00   1.93988264e-01   1.52465856e+00   1.39339995e+00\n",
      "   1.23936534e+00  -6.42594039e-01   1.00871944e+00   2.13545680e+00\n",
      "  -2.39146277e-01   6.61331058e-01  -9.39238369e-01  -7.76297987e-01\n",
      "  -9.31452513e-01   7.02217221e-01  -5.03405090e-03  -1.40679336e+00\n",
      "   8.67836893e-01  -9.13447380e-01  -8.04454207e-01  -7.52391577e-01\n",
      "  -1.99479107e-02  -3.48720551e-01  -7.84446120e-01   4.43306625e-01\n",
      "  -1.38111293e-01  -1.53317082e+00   4.09873158e-01   1.09160674e+00\n",
      "  -8.51960599e-01   5.40492646e-02  -1.14873099e+00  -1.02224505e+00\n",
      "   5.08039653e-01  -6.03672326e-01   1.18956774e-01  -7.07096577e-01\n",
      "   1.06519067e+00  -1.59247291e+00  -1.57608700e+00   5.53981960e-01\n",
      "  -8.47136557e-01  -4.52032655e-01  -2.38137767e-02  -1.54245210e+00\n",
      "   1.71378648e+00  -1.17304945e+00  -1.61000156e+00   6.77232802e-01\n",
      "  -8.29816461e-01  -4.77830052e-01  -2.56028795e+00  -3.44330609e-01\n",
      "  -5.15836058e-03  -1.64362133e+00   1.69068551e+00   2.93226838e-01\n",
      "  -2.23923191e-01  -9.25156772e-01  -1.13970113e+00  -1.25478530e+00\n",
      "  -8.08502972e-01  -1.49635628e-01  -8.87716055e-01  -2.25039124e+00\n",
      "   3.29445869e-01   1.26759505e+00   5.89319229e-01   1.50855160e+00\n",
      "  -8.10275316e-01  -1.14620996e+00   2.53478408e-01  -1.77769840e+00\n",
      "  -2.09448719e+00   4.23297912e-01   6.94229919e-03  -4.40711170e-01\n",
      "   1.28636733e-01  -1.81619990e+00   6.28080845e-01  -6.46824062e-01\n",
      "   1.73239052e-01  -7.69640505e-01   9.81099606e-01  -1.35971367e-01\n",
      "  -4.32013243e-01  -1.06801879e+00   1.23934305e+00  -1.56593466e+00\n",
      "   2.83674240e-01   9.98023972e-02  -8.45852137e-01  -7.27468252e-01\n",
      "  -6.68513179e-01   1.66691315e+00  -3.69820744e-01   8.90170038e-01\n",
      "   2.84130890e-02   6.80921137e-01   8.36860180e-01   9.63834405e-01\n",
      "   8.58464897e-01   1.78416923e-01   3.30660999e-01   3.69789332e-01\n",
      "   1.47861153e-01  -3.89627427e-01  -2.35125750e-01  -1.35470724e+00\n",
      "  -1.10436320e+00   1.79767758e-02   9.27715480e-01  -9.80296314e-01\n",
      "   5.71311653e-01   4.99001741e-02   1.02027930e-01  -6.27357900e-01\n",
      "  -9.88215089e-01   1.08862948e+00   9.19393957e-01   1.64117944e+00\n",
      "  -1.04321766e+00   6.70277536e-01   4.25456822e-01  -7.08908498e-01\n",
      "  -1.10061586e+00   1.91142642e+00  -6.28247023e-01  -8.16309512e-01\n",
      "  -7.67606139e-01  -8.99044633e-01  -1.22194254e+00  -2.01205564e+00\n",
      "  -1.90387750e+00  -1.07382393e+00  -4.56143409e-01   7.13032782e-02\n",
      "  -3.77161384e-01   2.61798888e-01   2.15977407e+00   3.37939143e-01\n",
      "  -7.34397247e-02  -3.61748785e-01  -4.24241513e-01   6.34891540e-02\n",
      "   5.82629979e-01   4.85710859e-01   2.00357169e-01  -6.46289408e-01\n",
      "   1.52512658e+00  -1.47554040e+00  -5.33872172e-02  -6.15987293e-02\n",
      "   1.36913526e+00  -3.20378840e-01  -1.50043331e-02   7.80413270e-01\n",
      "  -2.62816280e-01   9.82054651e-01   6.11349761e-01  -1.39179811e-01\n",
      "  -7.91251361e-01  -2.10169864e+00   1.51137781e+00  -1.36391366e+00\n",
      "  -5.38911223e-02  -4.77023840e-01  -6.19422555e-01   5.17902792e-01\n",
      "   1.93160728e-01   9.80396345e-02  -7.19597876e-01  -8.95540357e-01\n",
      "  -1.53677445e-02   1.22553051e-01  -4.99888480e-01   5.38899660e-01\n",
      "   7.46504739e-02   3.00126106e-01  -3.29246446e-02   1.17582309e+00\n",
      "  -4.19212490e-01  -1.28419828e+00   8.36820483e-01  -8.00640404e-01\n",
      "   9.07710969e-01  -4.29852903e-01   6.54367387e-01   1.52870476e+00\n",
      "  -9.96022522e-02  -1.30002046e+00  -3.61510783e-01  -8.84708643e-01\n",
      "  -4.22025293e-01   1.48515439e+00  -1.91484421e-01  -1.28258371e+00\n",
      "  -1.86176908e+00  -1.41109788e+00   6.41693950e-01  -5.61667264e-01\n",
      "  -7.03883946e-01  -8.62240672e-01   7.46035576e-01   4.63883072e-01\n",
      "   4.23524454e-02   3.16004068e-01   9.24452007e-01  -3.03953052e-01\n",
      "   8.71868193e-01   9.25615609e-01  -1.05239880e+00  -3.40491533e-01\n",
      "  -5.94672680e-01  -1.71079099e-01  -1.05369544e+00   8.05117667e-01\n",
      "  -2.55329013e-01  -3.09317797e-01   7.60524511e-01  -3.83099437e-01\n",
      "   1.37989855e+00  -5.80648124e-01   4.77636456e-01  -1.36449188e-01\n",
      "   3.46225619e-01   3.94118845e-01  -1.16857648e+00  -6.52530268e-02\n",
      "  -9.09818888e-01  -1.10794282e+00  -9.34838831e-01   1.39538085e+00\n",
      "  -4.56564605e-01   3.32861468e-02   7.46139526e-01   2.64533567e+00\n",
      "   2.40613192e-01  -1.62406075e+00  -5.63888788e-01   1.88130975e+00\n",
      "   8.95773768e-02   1.62431228e+00   1.00419259e+00  -3.88153782e-03\n",
      "  -3.05627614e-01   2.88628399e-01  -4.66451019e-01   1.81114638e+00\n",
      "   9.76743340e-01  -1.65329659e+00  -8.66378248e-02   1.60419798e+00\n",
      "  -4.76469308e-01  -6.88658595e-01  -2.84909774e-02   8.69678736e-01\n",
      "   1.30077958e-01   1.15090065e-01  -1.16273057e+00  -1.68761325e+00\n",
      "   1.30130613e+00  -4.67116803e-01  -2.27808505e-01   8.24380755e-01\n",
      "   1.18332051e-01  -7.08361864e-01   2.04973757e-01  -1.19296646e+00\n",
      "  -6.90116823e-01  -9.56261754e-01  -8.56289804e-01   1.72502077e+00\n",
      "   3.35205764e-01   4.14294809e-01  -1.16277504e+00  -1.21834151e-01\n",
      "   8.29951018e-02   1.53347325e+00   2.62689888e-01  -8.04365054e-02\n",
      "  -5.99067152e-01  -5.36751747e-01  -3.80344570e-01  -1.43468094e+00\n",
      "  -3.47604416e-02   1.12018847e+00  -4.41729933e-01   1.10997272e+00\n",
      "   1.84469104e+00  -1.00255418e+00   2.68919151e-02   1.61322355e+00\n",
      "  -5.66918969e-01  -2.17596745e+00   9.37635541e-01   1.79851472e+00\n",
      "   2.78573930e-01   1.10228217e+00  -1.96740544e+00  -1.44250199e-01\n",
      "   1.92589915e+00  -6.25535131e-01   4.84952442e-02  -1.37869278e-02\n",
      "   1.23148167e-03   2.73699909e-01  -2.02091873e-01   1.49260625e-01\n",
      "   9.94437754e-01  -4.01591331e-01   1.85059324e-01  -1.41426897e+00\n",
      "   4.04417574e-01   4.72418189e-01   3.37041736e-01  -1.12909901e+00\n",
      "   6.38968885e-01   6.65482581e-01  -7.87447751e-01  -2.52302766e-01\n",
      "   3.89867067e-01   7.14707434e-01   1.21199095e+00  -2.87939370e-01\n",
      "   9.46372271e-01   5.94347239e-01   2.37709522e+00   1.39159784e-01\n",
      "   1.45428568e-01   8.83213654e-02  -1.13000464e+00   2.31321859e+00\n",
      "   7.66114473e-01   5.74923038e-01   1.62794197e+00   2.05305323e-01\n",
      "   1.16905642e+00  -3.46430510e-01   6.47110701e-01   2.44277969e-01\n",
      "  -1.02034497e+00   2.25842094e+00   2.07316804e+00  -1.17188001e+00\n",
      "  -7.36482918e-01   6.88529387e-02  -6.39872532e-03  -2.32047009e+00\n",
      "  -7.66791582e-01   1.33282256e+00  -2.64927536e-01  -1.97675776e+00\n",
      "  -2.27156067e+00  -1.18645215e+00  -4.78246480e-01  -6.00752950e-01\n",
      "   4.22772169e-02   1.32677448e+00  -4.49970037e-01   2.91854620e-01\n",
      "   1.62346792e+00   5.02136052e-01   5.78853413e-02  -7.78745890e-01\n",
      "  -9.37589765e-01  -5.08142114e-01   2.14413142e+00   7.76806951e-01\n",
      "  -9.41570625e-02   1.31939256e+00  -2.69332826e-01  -4.23795916e-02\n",
      "   1.18777883e+00   4.89888847e-01  -4.34926242e-01   5.78123450e-01\n",
      "   2.34144896e-01   7.98548460e-01  -3.14464480e-01   1.79942250e+00\n",
      "  -7.73119807e-01   4.28186953e-01   4.26568002e-01   2.19600067e-01\n",
      "   9.45635736e-01   5.71202338e-01  -7.76314676e-01  -3.13368171e-01\n",
      "   2.66629636e-01  -8.61841321e-01   4.91327718e-02   1.61553156e+00\n",
      "   3.51667404e-01   2.04406714e+00   7.92030871e-01  -6.03373945e-01\n",
      "   3.62912714e-01  -6.96331739e-01   1.51741350e+00  -6.05584383e-02\n",
      "   1.37616384e+00  -3.21114808e-01  -6.81686878e-01  -9.06758189e-01\n",
      "   1.85290730e+00   1.35388660e+00  -2.56525725e-01   7.53408313e-01\n",
      "  -1.43091190e+00  -1.12154841e+00   1.81936026e+00   1.89721912e-01\n",
      "  -4.23926353e-01   5.71729302e-01  -1.31617320e+00   7.32451141e-01\n",
      "   1.97948188e-01  -2.03759015e-01  -3.72223020e-01   2.14365673e+00\n",
      "   1.54204774e+00   5.47505856e-01   1.50411808e+00   7.39319801e-01\n",
      "  -7.20564842e-01   1.11655402e+00   8.96830320e-01  -1.14790738e+00\n",
      "   2.23555160e+00  -1.79608035e+00   1.94624031e+00   3.99505436e-01\n",
      "   1.23826218e+00   5.45640349e-01  -6.04639411e-01   4.43602979e-01\n",
      "   6.23401880e-01  -1.34206653e+00   9.75546300e-01  -4.82220858e-01\n",
      "   1.20548677e+00   7.08733320e-01   1.91448116e+00  -7.61577860e-02\n",
      "  -7.22793460e-01  -7.30630994e-01   8.28325972e-02   7.49743640e-01\n",
      "  -2.07761168e+00  -1.50539207e+00  -1.26998901e+00   9.08437133e-01\n",
      "  -3.37159365e-01  -6.33529007e-01  -1.15425026e+00   4.15020883e-01\n",
      "   9.40151095e-01  -4.78021428e-02   1.80592763e+00   3.63087863e-01\n",
      "   7.49627113e-01   1.83108604e+00  -1.25663206e-01   2.13565990e-01\n",
      "  -7.59451389e-01   1.92369342e+00   1.33620965e+00   9.34564918e-02\n",
      "  -7.33474731e-01  -5.67230284e-01   4.63840067e-01   1.17775118e+00\n",
      "  -2.23757291e+00   1.13111007e+00   7.45937467e-01   1.15166569e+00\n",
      "   1.66817963e+00   3.90301371e-04   1.88100791e+00   1.20592284e+00\n",
      "   2.94540435e-01   8.22472930e-01   6.16415560e-01   1.16532147e-01\n",
      "  -1.10869616e-01   7.11772323e-01   2.78443909e+00   1.39470208e+00\n",
      "  -6.18349135e-01   1.47669055e-02   2.60375977e+00   1.87900352e+00\n",
      "   1.05078804e+00   1.35921228e+00  -2.58311510e-01  -3.44305634e-02\n",
      "   5.34054518e-01  -1.17165864e-01  -2.22820356e-01  -1.77761018e+00\n",
      "   1.72898844e-01   1.59001768e-01  -5.49453318e-01  -5.65769196e-01\n",
      "  -8.80106926e-01  -5.65599024e-01  -1.27153909e+00   1.54464424e+00\n",
      "  -1.93732595e+00  -1.58274725e-01   1.70995843e+00   1.03362942e+00\n",
      "   6.78675115e-01  -9.35876966e-01   6.68982387e-01   3.58086139e-01\n",
      "   3.00334930e-01  -4.72517997e-01   7.26323783e-01  -1.06102459e-01\n",
      "  -1.98668346e-01   1.35242879e+00   2.91553348e-01   5.09381652e-01\n",
      "   1.93793461e-01  -1.41599014e-01   9.19218421e-01  -3.16136509e-01\n",
      "  -1.40197444e+00   1.04442549e+00   1.13405848e+00  -3.84309024e-01\n",
      "   5.19327462e-01  -1.96654111e-01   1.13297570e+00  -7.56163776e-01\n",
      "   9.02142465e-01  -1.06182706e+00   1.17910959e-01  -2.73835480e-01\n",
      "  -8.51633191e-01   7.41013214e-02  -2.92436868e-01  -2.93582231e-01\n",
      "   8.54145229e-01   1.05671629e-01  -3.76791596e-01   2.12312865e+00\n",
      "  -5.84455729e-01   1.45955971e-02   2.32100748e-02  -5.63644946e-01\n",
      "  -3.22341144e-01  -3.99383813e-01   1.70532063e-01  -6.32174760e-02\n",
      "  -2.25287601e-01   1.02938449e+00   8.56115997e-01   4.52138126e-01\n",
      "   3.22132826e-01  -5.57952464e-01  -3.60112071e-01   5.14381111e-01\n",
      "  -2.71247816e+00   1.25371799e-01  -1.86882722e+00  -1.41053355e+00\n",
      "  -1.27154124e+00  -6.56068504e-01   1.06410646e+00  -9.58711505e-01\n",
      "   8.13451469e-01  -3.16259786e-02   5.81100762e-01  -6.33950770e-01\n",
      "   3.03824306e-01  -7.91128576e-01   3.91977370e-01  -1.72613299e+00\n",
      "  -1.78149492e-01   1.39442313e+00  -1.46073680e-02   6.60841912e-02\n",
      "   1.51342601e-01   9.63400677e-02  -1.06340301e+00  -1.64267826e+00\n",
      "   6.84162974e-01   1.44634211e+00   1.54590935e-01   5.43448389e-01\n",
      "   9.49166194e-02  -6.34862661e-01   3.48145247e-01  -7.94101298e-01\n",
      "   3.09563637e-01  -1.01746869e+00  -6.21416867e-01   4.70256865e-01\n",
      "  -9.91893291e-01  -9.78734970e-01   6.89836264e-01  -3.20287943e-01\n",
      "  -1.65223622e+00   4.49854225e-01  -1.12480283e+00  -1.36727795e-01\n",
      "   4.74816501e-01  -8.51136267e-01   2.50535637e-01  -7.07354486e-01\n",
      "  -1.09250617e+00  -6.17739379e-01  -1.82850146e+00  -8.29927325e-01\n",
      "  -1.11841154e+00  -7.65853167e-01  -2.74281770e-01  -1.62132418e+00\n",
      "  -1.00797951e+00  -4.12419021e-01  -5.00053585e-01   3.77448142e-01\n",
      "  -1.12590921e+00  -2.22131759e-01  -2.49198452e-02   9.32981610e-01\n",
      "  -1.04736161e+00  -1.30087733e+00   1.17142034e+00   2.56221473e-01\n",
      "   1.78799480e-02   1.47631097e+00   7.96515584e-01   1.74776757e+00\n",
      "   2.60416895e-01   2.40191042e-01   8.36046159e-01  -2.04300499e+00\n",
      "   1.68455064e+00  -1.13684893e+00  -4.60266739e-01  -7.44868040e-01\n",
      "  -1.51777595e-01  -1.17909205e+00   1.88417524e-01   9.52252567e-01\n",
      "   7.53662527e-01  -1.49801123e+00   2.40582705e-01   2.47313094e+00\n",
      "  -1.05812740e+00  -1.96104920e+00  -1.76071346e-01  -2.78117657e+00]\n",
      "1. Param \"b1\"\n",
      "(256,)\n",
      "1.1731\n",
      "2. Param \"W2\"\n",
      "(256, 256)\n",
      "[-1.85779989 -0.41628319 -0.50051767 -0.60785902  0.18484838 -0.52552944\n",
      " -1.18841207  0.7408964  -0.85244435  0.03203035 -0.90505803 -1.8525635\n",
      "  0.61512411 -0.04451932  0.95532519 -1.12629676  0.37805089  0.84669322\n",
      " -1.95747769 -1.57131195 -1.66773796  1.61979175 -0.27571401 -1.42890179\n",
      " -1.37895143  0.02466393  0.03227331  0.87976199  0.1959898   1.46785378\n",
      " -0.34419852 -0.91376346 -1.45420468 -0.22557904 -0.29421255  1.02967441\n",
      "  1.24518323 -1.54586875 -0.10119519 -0.94021499 -0.49637985 -1.80715501\n",
      " -2.77899575 -1.21633077  0.6411919   1.17478311  0.44291502 -0.32760113\n",
      " -0.78818446 -0.43035939  0.06449582 -0.90231764  0.89651757 -1.47404397\n",
      " -0.13086413  0.29634249  0.88907313 -2.00494957 -2.03951573 -2.31463933\n",
      "  0.17316256  0.30341268  0.21356104 -0.96837163 -0.054764   -0.68475521\n",
      " -1.3183037   1.12128377 -2.47486043  0.92373687 -2.37366629  0.50035548\n",
      "  1.42868197  1.54760528  0.36573556 -0.02362414  0.22538038 -1.05400789\n",
      " -1.13095379 -0.38554275 -1.49861538  1.45510137 -0.97399968  1.11753917\n",
      "  0.17945106 -0.274322   -0.13059933 -1.93728507 -1.71465194  1.55133486\n",
      " -0.1367411   0.10414615 -0.07705253 -0.49798247 -0.3324326   0.19456784\n",
      "  0.27801198  0.90232378  0.98920888 -1.06639588  1.97558367  0.00643893\n",
      " -0.30735591 -2.08710766 -0.32205048 -0.3251251  -0.88388652 -1.5867573\n",
      " -0.12905735  2.08982611  0.26880956  1.37380052 -1.40927935  1.80445313\n",
      " -0.0704243  -0.88277137  0.64060551  1.81984138 -0.77866292  1.13914442\n",
      " -1.48693478  0.64548451 -1.13524175  0.40546617  1.10345137  0.48891324\n",
      "  0.28005242  0.73677874 -0.17920512  0.20407744  0.66757512 -1.4056859\n",
      " -2.45806813 -1.98275173 -0.45496768  0.73673373  0.13465762  0.09074698\n",
      "  1.75544536 -1.43727648  0.19541048  0.24897479 -1.05939174  0.18957253\n",
      " -0.07514346 -1.27031708 -0.14569294 -0.01148049  1.14363551 -0.04500166\n",
      " -1.68466389 -0.10688533  0.8324073  -0.45258451 -1.11634469  2.46698523\n",
      " -0.15532579 -0.33408755 -0.07988735  0.28242245  0.45494983  1.40842068\n",
      " -0.74394768 -0.00714053 -1.97599232  3.58932638 -1.44768965  1.38507581\n",
      "  1.80035412  0.61927307  2.13031077  0.23324189  0.71534145 -0.40490347\n",
      "  0.97649956 -0.65271306  1.27893019  0.61633462 -0.89399815  0.24783191\n",
      " -0.18920557  0.82288957 -0.50049055 -1.66399026  0.94764668 -0.2464665\n",
      "  1.08956492 -1.4030211  -1.27496433 -0.46012709  0.37312219 -0.10684844\n",
      " -0.02223246 -0.40871173  0.71887034  2.72276068  0.07265497 -0.79790449\n",
      "  0.22669764 -0.9170599  -0.38344967  1.09298706 -0.59008765  0.70962149\n",
      "  0.28632888 -1.04753792 -0.89718634 -0.57733202 -0.67433131  0.00665103\n",
      "  0.57918686  1.97387147 -0.08532448  0.24483907 -0.05940194 -0.66468316\n",
      " -0.77234226 -1.10482717 -0.95109117  1.18421209  1.31168497 -1.42641294\n",
      "  0.18995124 -0.11215045  0.22171469  0.91135263  0.72016376  2.0723393\n",
      " -0.2302383  -0.69091982 -0.79121834  1.04829204 -1.35437572 -0.1647149\n",
      " -0.58438694 -0.35220364  1.03487086 -0.04376953  2.24792147 -0.16089411\n",
      " -1.21114087 -0.35490918 -0.58371651  0.52136821 -0.34603515 -0.50994235\n",
      " -1.71702039  1.42701566 -0.37162709 -2.30147934 -1.00331342 -0.15335982\n",
      "  1.78486681 -2.73667288  1.43133473 -1.27263916]\n",
      "3. Param \"b2\"\n",
      "(256,)\n",
      "0.738783\n",
      "4. Param \"Wout\"\n",
      "(10, 256)\n",
      "[-1.03803635  0.33403882 -0.38138002 -0.12119953 -0.64441329 -1.19551122\n",
      " -0.39239821  0.16695742 -0.93922043  0.62227321  0.26522857  1.17137098\n",
      " -0.71378702 -0.94677687  0.17804386  1.29430914 -1.50048423  0.02534585\n",
      " -0.72055072 -1.00808048 -1.77754831 -0.14478038  0.4086158  -0.28675202\n",
      " -1.18376541 -1.200104   -0.61721504 -2.64730668 -0.3405337  -0.14488029\n",
      " -0.07269595  0.54034889  0.81599414  0.50242943 -0.12688382  1.91721511\n",
      " -1.37132025 -0.48262829 -0.96502423  0.03573767  0.91857606 -0.87395954\n",
      "  0.96370447  0.26497775 -1.24906993 -1.38104689  0.37096068 -0.5888682\n",
      " -0.95869458 -1.48174155  0.93232691  0.62789857 -0.28456476 -0.05299685\n",
      "  0.99250543 -1.16098535 -0.64246649 -0.28346676 -0.81097776  1.29440153\n",
      " -0.60756594 -0.75037211 -0.51606107 -0.99839944 -1.61676419 -0.71624917\n",
      "  0.2610918   0.93000758  0.2171225   1.13309634  0.22112964  0.87452948\n",
      " -0.21771978  0.16980182 -0.10724461 -0.07791338 -1.92541528  0.12596856\n",
      " -0.28047299  0.09284457  0.2169473   2.21376514 -1.18678963  0.43917286\n",
      " -0.50044835  0.57582879  1.1256156  -0.28011411  1.06230164  0.07971251\n",
      " -1.19920266  2.24185586 -0.67120254  0.04683563 -1.93757689  1.14299822\n",
      " -0.20091462  0.95597619  0.44355926  0.16451059  0.56505245  2.60756111\n",
      " -0.25514504 -0.65644443 -0.29283264 -1.58489954 -0.61540133  1.21498704\n",
      "  0.42253602 -0.19683568  1.17681968 -1.25561655  1.32663822  1.73057115\n",
      "  0.28171372 -0.24664254  1.1257571   2.71515131 -0.40263012 -2.27976561\n",
      " -1.52836084 -1.73509336 -0.72974581  0.4089258  -0.72419226 -0.12615353\n",
      " -0.88763279  0.62446648 -0.56515193 -1.41512764  0.57043517 -0.36239997\n",
      "  1.74125922 -3.03279948  0.30006704  1.6673336   1.15842628 -0.0947968\n",
      "  0.0261027  -0.07331304 -1.41979301 -1.37305331  0.55183381 -1.24765182\n",
      " -0.67366725 -1.00822163 -2.03040504  0.08296261 -0.19694959  0.97002119\n",
      " -0.39200047 -0.53524566 -1.27252901 -0.42368868 -0.27401531  1.28752518\n",
      " -0.2619482   0.87176698 -1.68126011  0.23335777 -0.11179904  1.17787623\n",
      "  0.13662629 -0.07012448  1.61005855  0.31105617 -1.95145905 -1.76638114\n",
      " -0.37448388  0.62182862  1.79517817 -0.69233054  1.26829875 -1.09154201\n",
      "  1.95066953  0.67346966 -1.09540975 -0.38140562 -0.08725056 -0.13085936\n",
      "  0.88837987  2.88228941 -0.1874596   0.96141797  1.80445695 -0.77869815\n",
      " -0.50472951  0.49633417 -0.50581449  0.01876415 -0.23574421  1.29697716\n",
      " -0.43490943  1.51054609 -1.26190186  1.90923989 -0.08853103  0.54126644\n",
      " -0.11604956 -0.47864535  0.89535022 -0.36653745  0.70705575 -0.80396825\n",
      " -0.02794082  1.97073257 -1.17437279 -1.38723457 -0.89142436 -0.4129982\n",
      " -0.74088037 -1.17185771  1.41385961 -0.00824897  0.54497266 -1.47366655\n",
      "  0.14252476  0.68701833  0.24678375  1.3254559  -0.56929994  0.39387202\n",
      "  0.53472489 -0.05294128  0.32907367 -0.68367469  0.83485615  0.31541812\n",
      "  2.36212349  2.46822548 -0.07650296  0.15597692 -0.21493019 -1.44532168\n",
      "  1.54877973 -1.37499762 -0.13830547  1.11436749 -0.97454315  0.69013458\n",
      " -1.58734298  0.05253549 -1.07376075 -0.61688191 -0.23290659  1.41054225\n",
      " -1.877702    2.29913998 -1.12234676  0.74230212  0.48211175 -0.24128778\n",
      " -0.43825075  0.57676458  1.62271488  0.47343868]\n",
      "5. Param \"bout\"\n",
      "(10,)\n",
      "-0.64086\n"
     ]
    }
   ],
   "source": [
    "### Save parameters, inputs and targets into JSON files\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def SimpleEncode(ndarray):\n",
    "    return json.dumps(ndarray.tolist())\n",
    "#def SimpleDecode(jsonDump):\n",
    "#    return np.array(json.loads(jsonDump))\n",
    "\n",
    "param_names = [\"W1\", \"b1\", \"W2\", \"b2\", \"Wout\", \"bout\"]\n",
    "params = [trained_weights['h1'].transpose(), trained_biases['b1'],\n",
    "          trained_weights['h2'].transpose(), trained_biases['b2'],\n",
    "          trained_weights['out'].transpose(), trained_biases['out']]\n",
    "\n",
    "i = 0\n",
    "for param_name in param_names:\n",
    "    print(str(i) + \". Param \\\"\" + param_name + \"\\\"\")\n",
    "    json_string = SimpleEncode(params[i].astype(np.float32))\n",
    "    print(params[i].shape)\n",
    "    #%timeit SimpleDecode(json_string)\n",
    "    with open(param_name + '.json', 'w') as outfile:\n",
    "        outfile.write(json_string)\n",
    "        outfile.close\n",
    "    print(params[i][0])\n",
    "    i = i + 1\n",
    "    \n",
    "# Test images\n",
    "json_string = SimpleEncode(mnist.test.images[:100].astype(np.float32))\n",
    "with open('test_images.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "    outfile.close\n",
    "# Test labels\n",
    "json_string = SimpleEncode(mnist.test.labels[:100].astype(np.float32))\n",
    "with open('test_labels.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "    outfile.close\n",
    "#7.12256670e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output[:2]:\n",
      "[[ -237.15965271   642.08825684   594.06115723   653.9631958    -13.95187664\n",
      "    333.62982178  -856.8449707   1259.04553223   536.81286621\n",
      "    784.20300293]\n",
      " [ -120.90952301   277.98376465  1602.71386719   586.84735107\n",
      "   -680.02850342   254.78291321   188.31906128  -226.9961853    737.79748535\n",
      "   -544.57794189]]\n",
      "Output[:2] maxed:\n",
      "[7, 2]\n",
      "Correct[:2]:\n",
      "[7, 2]\n"
     ]
    }
   ],
   "source": [
    "### Save Tensorflow's forward propagation results into JSON ifle\n",
    "inputs_total = 10000\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, trained_weights, trained_biases)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Produce outputs\n",
    "    result = sess.run([pred], feed_dict={x: mnist.test.images[:inputs_total]})\n",
    "    \n",
    "# Print results\n",
    "print(\"Output[:2]:\")\n",
    "print(result[0][:2])\n",
    "print(\"Output[:2] maxed:\")\n",
    "print([list(decision).index(max(decision)) for decision in result[0][:2]])\n",
    "print(\"Correct[:2]:\")\n",
    "print([list(decision).index(max(decision)) for decision in mnist.test.labels[0:2]])\n",
    "    \n",
    "# Backup results\n",
    "json_string = SimpleEncode(result[0].astype(np.float32))\n",
    "with open('test_tf_results.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "    outfile.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
