{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A Convolutional Network implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')#padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='VALID')#padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):#, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    #conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    #conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    #fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['wout']), biases['bout'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-62-cb5697f3961f>:32 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([10, 10, 1, 16])),#5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([10, 10, 16, 32])),#5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([10*10*32, 256])),#7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'wout': tf.Variable(tf.random_normal([256, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([16])),\n",
    "    'bc2': tf.Variable(tf.random_normal([32])),\n",
    "    'bd1': tf.Variable(tf.random_normal([256])),\n",
    "    'bout': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases)#, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "\n",
    "#matplotlib.use('Agg')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    w = sess.run(weights)\n",
    "    #print(w['wc1'])\n",
    "    obj = plt.pcolor(np.reshape(w['wc1'][:, :, 0, 0], (25, 25)))\n",
    "    set_cmap('gray')\n",
    "    colorbar()\n",
    "    \n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 28899.382812, Training Accuracy= 0.25781\n",
      "Iter 2560, Minibatch Loss= 25020.455078, Training Accuracy= 0.35156\n",
      "Iter 3840, Minibatch Loss= 15073.139648, Training Accuracy= 0.57031\n",
      "Iter 5120, Minibatch Loss= 13870.677734, Training Accuracy= 0.55469\n",
      "Iter 6400, Minibatch Loss= 8358.896484, Training Accuracy= 0.67188\n",
      "Iter 7680, Minibatch Loss= 6972.493164, Training Accuracy= 0.68750\n",
      "Iter 8960, Minibatch Loss= 7517.324707, Training Accuracy= 0.71094\n",
      "Iter 10240, Minibatch Loss= 10708.041016, Training Accuracy= 0.61719\n",
      "Iter 11520, Minibatch Loss= 7424.993652, Training Accuracy= 0.70312\n",
      "Iter 12800, Minibatch Loss= 9519.800781, Training Accuracy= 0.67969\n",
      "Iter 14080, Minibatch Loss= 4374.840332, Training Accuracy= 0.75781\n",
      "Iter 15360, Minibatch Loss= 5486.693359, Training Accuracy= 0.72656\n",
      "Iter 16640, Minibatch Loss= 4911.049805, Training Accuracy= 0.78906\n",
      "Iter 17920, Minibatch Loss= 5596.292969, Training Accuracy= 0.74219\n",
      "Iter 19200, Minibatch Loss= 4321.762207, Training Accuracy= 0.75781\n",
      "Iter 20480, Minibatch Loss= 4304.134766, Training Accuracy= 0.78906\n",
      "Iter 21760, Minibatch Loss= 3520.607422, Training Accuracy= 0.82031\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.832031\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    acc = 0\n",
    "    #while step * batch_size < training_iters:\n",
    "    while acc < 0.8:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})#,\n",
    "                                                              #keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print (\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))\n",
    "    # Backup params\n",
    "    trained_weights = sess.run(weights)\n",
    "    trained_biases = sess.run(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n",
      "Saved param \"bc2\"\n",
      "(10, 10, 16, 32)\n",
      "Saved param \"wc2\"\n",
      "(10, 10, 1, 16)\n",
      "Saved param \"wc1\"\n",
      "(256, 3200)\n",
      "Saved param \"wd1\"\n",
      "(10,)\n",
      "Saved param \"bout\"\n",
      "(16,)\n",
      "Saved param \"bc1\"\n",
      "(10, 256)\n",
      "Saved param \"wout\"\n",
      "(256,)\n",
      "Saved param \"bd1\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def SimpleEncode(ndarray):\n",
    "    return json.dumps(ndarray.tolist())\n",
    "\n",
    "dir_name = \"experiment\"\n",
    "# Create directory\n",
    "if not os.path.isdir(dir_name):\n",
    "    os.mkdir(dir_name)\n",
    "    \n",
    "trained_params = {} #**trained_weights, **trained_biases}\n",
    "for weight_key in trained_weights:\n",
    "    if len(trained_weights[weight_key].shape) == 2:\n",
    "        # MLP weights\n",
    "        trained_params[weight_key] = trained_weights[weight_key].transpose()\n",
    "    else:\n",
    "        # Convolutional weights\n",
    "        trained_params[weight_key] = trained_weights[weight_key]\n",
    "trained_params = {**trained_params, **trained_biases}\n",
    "    \n",
    "for param_name in trained_params:\n",
    "    json_string = SimpleEncode(trained_params[param_name].astype(np.float16))\n",
    "    print(trained_params[param_name].shape)\n",
    "    with open(dir_name + '/' + param_name + '.json', 'w') as outfile:\n",
    "        outfile.write(json_string)\n",
    "        outfile.close\n",
    "    print(\"Saved param \\\"\" + param_name + \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 images, shape: (1, 784)\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = 1\n",
    "\n",
    "test_images, test_targets = mnist.test.next_batch(100)\n",
    "\n",
    "test_batch_images = test_images[start:end]\n",
    "test_batch_targets = test_targets[start:end]\n",
    "\n",
    "# Save test images\n",
    "json_string = SimpleEncode(test_batch_images.astype(np.float32))\n",
    "with open(dir_name + '/test_images_n' + str(end-start) + '.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "    outfile.close\n",
    "    \n",
    "print(\"Saved \" + str(test_batch_images.shape[0]) + \" images, shape: \", end='')\n",
    "print(test_batch_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward-propagating...\n",
      "WARNING:tensorflow:From <ipython-input-66-48b0c90c59d9>:22 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Inputs[0]:\n",
      "213.753\n",
      "Weights['wd1'][0]:\n",
      "[-0.47187206  1.08341396 -1.47720969 -0.19636898 -0.51985645  0.24864505\n",
      " -1.24037206 -0.4832938   0.00023006  0.40612677  0.08893027  0.39518809\n",
      " -0.29394531 -1.82325184 -0.23145139 -1.00753617  1.32293379  0.33850086\n",
      "  1.24928176  0.69410473 -0.79484934 -0.25488058 -0.29076239  0.93654656\n",
      " -1.05741274  0.62239391  0.54844779  1.68540788  1.09214199  0.22519499\n",
      "  1.0957396  -0.71046937  1.32815003 -0.15523241 -1.69996715 -0.21848178\n",
      " -0.74748725 -2.60405779 -1.58781004  0.30472574  1.17814505  0.15850191\n",
      " -0.52324247 -1.10162449  1.18046141  0.15323745  2.059165   -0.75512916\n",
      " -0.70019263  1.65853167  0.03873347 -0.24496233  0.07724958  0.40521377\n",
      "  0.54079425 -2.66528678 -0.11002549 -0.2445145  -0.87325329 -0.18451075\n",
      "  0.77185243  2.15242648 -0.23326361  1.63746047  0.77986103  0.9038437\n",
      " -0.82536131 -0.65774959 -0.33969179  0.42808837 -0.31729046 -0.44883105\n",
      "  1.74023783  0.69758874  1.99703574 -2.16369987  1.10064209 -1.02918315\n",
      " -0.75046468 -1.15374088  0.2760601  -0.03539434  0.82956529 -0.89005601\n",
      "  0.20729232 -0.20301145 -0.70656061 -1.22314763 -0.1714513   0.17492954\n",
      "  0.01379802  1.06726158  0.97715753  1.89758551 -0.13407506 -0.26722008\n",
      "  0.19033571  0.4569535   0.26969582  0.27704018  1.23741639  0.56696713\n",
      " -1.85365963 -0.36334762 -1.27875352 -0.80313951  0.81282145  2.15712214\n",
      "  1.57718885  1.5087167   1.13940322  1.15835047 -0.01972182  2.69229007\n",
      "  0.82352465  0.0832371   1.29002619  0.39259252  1.58912981 -1.30670822\n",
      " -0.81314951 -0.13763016 -2.08603215 -2.6960535   0.55072308  0.41766307\n",
      " -1.77367103  0.60134643 -1.95193672 -0.91254944  0.23692338 -0.53489858\n",
      "  0.06804836 -0.14906098 -2.08491063 -0.50554723  1.77769017 -0.81486291\n",
      "  0.86756521 -1.2987659   1.34545469  0.56938946 -1.0196867  -0.99590689\n",
      "  0.67765474 -0.46151409  0.98592216 -0.98899454  0.29422411 -0.38919702\n",
      " -1.13659453 -1.54170525 -1.15326154  2.0002234  -0.37304753  0.49902266\n",
      " -0.65255016 -0.05329243  1.09786975 -0.55856752 -1.9777633  -0.15308933\n",
      "  0.18204221 -1.69882166 -0.43009329 -2.14662004 -0.73472434  1.70017886\n",
      "  0.35358307 -0.90886098 -1.67722964  0.57382101 -0.10263586  0.25730929\n",
      " -1.66802526  0.4251765  -0.7634328   1.44259381 -0.18928178 -0.27772707\n",
      " -0.64162016  1.16137135  1.23737013  2.14466286  1.05509722 -0.35402998\n",
      " -1.4067744   0.95612001  0.63841897  1.59524858 -0.53176528 -0.89251918\n",
      " -1.46638536  0.52283329 -0.64224625 -0.66222775  2.08394957 -1.30237746\n",
      " -0.13611144 -0.69197613  1.31484818  0.34044504 -0.99050552  0.76327586\n",
      " -0.49396434  0.53890687  0.27552748 -0.51127982 -0.3208704  -0.17881782\n",
      "  0.47326165 -0.38509527 -0.71387291  0.03222506  0.09020812  1.23959231\n",
      "  0.10133541 -0.17953387  1.0695895  -1.2224685  -1.13137412  0.43245602\n",
      " -1.0954212   1.43609428 -0.94848841  0.32664418  1.67188764  0.59131753\n",
      "  0.61314768  0.74144095 -0.26159963  2.30181956  0.42111796  1.38296533\n",
      "  0.75203484  1.21044922 -0.67936867  0.51343673 -0.35221484  0.87292969\n",
      "  0.22211298 -0.05760947  0.06923582 -0.81914055  0.55657703  0.64785439\n",
      "  0.18015872 -1.49902415 -2.13108015  0.19585508 -1.23214328 -0.06429297\n",
      " -0.91824859  0.03115394  0.92509997 -0.98864126]\n",
      "Biases['bd1']:\n",
      "[-0.26423457 -0.40593493  1.12097681 -2.30548739 -1.05238545 -0.71223366\n",
      "  0.64237958 -0.32707441 -1.51533186 -0.40542004 -0.97858387  0.02795964\n",
      " -0.61027038 -2.15923619 -0.75081897 -1.03527343 -0.7281974   0.00211692\n",
      " -1.07677102 -0.20981631  0.07402043  0.04586753  0.2393048  -1.44396055\n",
      "  1.90334523  0.81858188  1.53846228 -1.02370691 -1.38126957 -2.2210238\n",
      " -0.86283731 -1.81341672 -0.5701797  -1.97736013  0.80729502  0.38495293\n",
      "  0.80632079 -0.06436224  1.26424515 -0.2817871   0.65622002  1.73051751\n",
      "  0.94801331  0.90904611 -0.41638991 -1.24503255 -0.65771186  1.13580942\n",
      " -0.59214604  0.15164295  1.30178273  0.67926174  1.33782029  0.78277802\n",
      " -0.25476289 -0.511347   -2.11936164 -0.84016865  0.663647    0.49832317\n",
      " -0.91023481  0.33334067  1.83900678 -1.3579402   0.66920006 -1.61284471\n",
      "  0.95024627 -1.8769995   0.87682253  1.04456496  0.45736176 -1.13627076\n",
      "  0.89204496  1.0860647  -0.74410748 -0.23686619 -1.89459181  1.29374146\n",
      "  0.07164002 -0.22151366  1.23447895  0.46805492  0.8527987  -0.55109578\n",
      " -0.54628068  0.99666637  0.198708   -0.16156964  0.02899203 -0.87580037\n",
      " -0.23299114 -0.64207101 -1.33872128  0.2885825   2.55720305  0.99439311\n",
      "  2.24995828  2.31677914 -0.90318125 -1.4227922   0.28806704  0.39421952\n",
      " -2.85628414 -1.05131662  1.27241039 -1.78633094  0.97665161  0.90088201\n",
      "  0.44612071 -0.06857347 -1.08910525 -0.50545841 -1.49268234 -2.04501271\n",
      " -0.92411691 -0.76346558 -1.90695882 -0.00423408 -0.41822493 -0.34086129\n",
      " -2.01639819  0.80993921 -0.91459662 -0.6827395  -1.76282656 -0.86032808\n",
      "  0.74939942  1.6999687  -0.6850729  -0.71347886  0.3586919  -0.41976401\n",
      "  0.27588639 -1.16485178 -0.31749427  0.58439296 -0.66933739 -1.79654217\n",
      "  0.77207434 -0.47375414 -0.29785472  0.13446766 -0.52492452 -0.35456941\n",
      "  0.13798442  0.69175088 -0.47303697  0.87620485 -0.30710754  0.44565615\n",
      " -0.22232677  1.24796033 -0.33186808 -1.18053055 -0.81887704 -1.64970446\n",
      "  0.44837219  0.90620941 -0.51823598 -0.18994796  1.44206023  2.34268332\n",
      "  0.54490471 -0.11555377  0.46293747  0.50475198 -0.64484411 -0.16791588\n",
      " -0.20351875  0.89385515  0.32734084 -2.45483351 -1.06628931 -1.90614831\n",
      " -0.76120985  0.15017188  1.30449116  0.00851683  1.15653408  0.91030353\n",
      "  0.17241727 -0.00586718 -0.30190161  0.64215213  0.25837666  0.91537732\n",
      " -0.19101651 -1.36993062 -0.79278207  2.66761518 -1.06283855 -0.22997503\n",
      "  0.26846492  0.16358691  1.13941145  1.47413194  0.51574427  0.97158372\n",
      " -1.06826663  0.72458321  0.68166488  0.1549172  -0.59466767  1.39046156\n",
      "  1.20117176  1.03989959  1.29722297 -1.2117362   0.31745127 -0.13800499\n",
      "  1.9728632  -0.72643632 -0.47642544  0.10448387  0.4095574   1.77047229\n",
      " -0.78056413  0.12583087  0.88081497  1.24086678 -0.88203114 -0.02789778\n",
      " -0.10303049 -0.87133396  0.13890865 -1.44099331  0.26298851 -1.48739111\n",
      "  1.50046647  2.34570146 -0.86171883 -0.54245085  1.52448893 -0.72663647\n",
      " -0.84903234 -0.69009274 -0.54981327 -0.10885137 -0.76255774  0.05691602\n",
      " -0.87109727  0.41730139 -0.42845339  1.64497674 -1.3881067   1.52576935\n",
      " -0.59143788 -0.42807028  0.26104632 -0.49053165 -0.74486649  0.06136478\n",
      " -0.45848376  1.63258934 -0.36872229 -1.99028814]\n",
      "Output[0]:\n",
      "(10,)\n",
      "[ -6499.22265625 -72997.84375       967.51171875  74171.3359375\n",
      " -70313.515625     -336.09765625 -52735.81640625 -67623.2734375\n",
      "  45543.6796875    -102.76367188]\n",
      "Output[0:1] maxed:\n",
      "[3]\n",
      "Correct[0:1]:\n",
      "[3]\n",
      "Saved results, shape: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "### Save Tensorflow's forward propagation results into a JSON file\n",
    "print(\"Forward-propagating...\")\n",
    "n_input = 784\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "# Convert arrays to tensors\n",
    "trained_weights_tensors = {}\n",
    "for weight_name in trained_weights:\n",
    "    trained_weights_tensors[weight_name] = tf.convert_to_tensor(trained_weights[weight_name].astype(np.float16).astype(np.float32))\n",
    "\n",
    "trained_biases_tensors = {}\n",
    "for bias_name in trained_biases:\n",
    "    trained_biases_tensors[bias_name] = tf.convert_to_tensor(trained_biases[bias_name].astype(np.float16).astype(np.float32))\n",
    "    \n",
    "# Construct model\n",
    "pred = conv_net(x, trained_weights_tensors, trained_biases_tensors)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    #run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    #run_metadata = tf.RunMetadata()\n",
    "    sess.run(init)\n",
    "    # Produce outputs\n",
    "    result = sess.run([pred], feed_dict={x: test_batch_images})#, options=run_options, run_metadata=run_metadata)\n",
    "    # Create the Timeline object, and write it to a json\n",
    "    #tl = timeline.Timeline(run_metadata.step_stats)\n",
    "    #ctf = tl.generate_chrome_trace_format()\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #if not os.path.isdir(dir_name + \"/results_tensorflow\"):\n",
    "    #    os.mkdir(dir_name + \"/results_tensorflow\")\n",
    "    #with open(dir_name + \"/results_tensorflow/\" + current_time.strftime(\"%d.%m.%Y-%H.%M.%S.\") + \n",
    "    #          str(int(current_time.microsecond / 1000)).zfill(3) + \".n\" + str(end-start) +\n",
    "    #          \".timeline.json\", 'w') as f:\n",
    "    #    f.write(ctf)\n",
    "\n",
    "# Print results\n",
    "verbose = True\n",
    "if verbose:\n",
    "    np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "    #print(\"Weights[0][0]:\")\n",
    "    #print(trained_weights)\n",
    "    i = 0\n",
    "    print(\"Inputs[\" + str(i) + \"]:\")\n",
    "    print(test_batch_images[i].sum())\n",
    "    #print(\"Weights['wc1'][0][0]:\")\n",
    "    #print(trained_weights['wc1'][0][0])\n",
    "    #print(\"Biases['bc1']:\")\n",
    "    #print(trained_biases['bc1'])\n",
    "    print(\"Weights['wd1'][0]:\")\n",
    "    print(trained_weights['wd1'][0])\n",
    "    print(\"Biases['bd1']:\")\n",
    "    print(trained_biases['bd1'])\n",
    "    print(\"Output[\" + str(i) + \"]:\")\n",
    "    print(result[0][i].shape)\n",
    "    print(result[0][i])\n",
    "    print(\"Output[0:\" + str(i+1) + \"] maxed:\")\n",
    "    print([list(decision).index(max(decision)) for decision in result[0][:i+1]])\n",
    "    print(\"Correct[0:\" + str(i+1) + \"]:\")\n",
    "    print([list(decision).index(max(decision)) for decision in test_batch_targets[:i+1]])\n",
    "\n",
    "# Save results\n",
    "json_string = SimpleEncode(result[0].astype(np.float32))\n",
    "with open(dir_name + '/test_tf_results_n' + str(end-start) + '.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "    outfile.close\n",
    "if verbose:\n",
    "    print(\"Saved results, shape: \", end='')\n",
    "    print(result[0].shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}